{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcript Summarization\n",
    "This notebook reads the transcript dataset and generates summaries using the Bert Extractive Summarizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are x methods of Bert Summarization\n",
    "* Bert Extractive Summarizer\n",
    "* SBert Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters to be considered for models\n",
    "* param ratio: Ratio of sentences to use.\n",
    "* param min_length: Minimum length of sentence candidates to utilize for the summary.\n",
    "* param max_length: Maximum length of sentence candidates to utilize for the summary.\n",
    "* param use_first: Whether or not to use the first sentence.\n",
    "* param algorithm: Which clustering algorithm to use. (kmeans, gmm)\n",
    "* param num_sentences: Number of sentences to use (overrides ratio).\n",
    "* param return_as_list: Whether or not to return sentences as list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from summarizer import Summarizer\n",
    "from summarizer.sbert import SBertSummarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ttg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-154-f5d8fbc521aa>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-154-f5d8fbc521aa>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    email = #lines[1]\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "email = #lines[1]\n",
    "m = re.search(\"[0-9][0-9]:[0-9][0-9]\", email)\n",
    "email[:m.start()] + email[m.end():]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m = re.sub(\"[0-9][0-9]:[0-9][0-9]\", '', lines[1])\n",
    "#m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/demo.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = ''.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = re.sub(\"[0-9][0-9]:[0-9][0-9]\", '', lines)\n",
    "lines = re.sub(\"[0-9]:[0-9][0-9]\", '', lines)\n",
    "lines = re.sub(\"\\'\", '', lines)\n",
    "lines = re.sub(\"\\n\", '', lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lines\n",
    "with open('data/siads697698/01_week-1/02_videos/05_how-to-do-a-standup.en.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = ''.join(lines)\n",
    "lines = re.sub(\"\\n\", ' ', lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I mentioned to you that we're going to do some biweekly stand-ups, so here's what to do in a stand-up. Some of you who might have worked at tech companies or similar organizations might already know about them, but if you're new, here is roughly what we're going to do. When it comes time for your stand-up, you're going to get on your webcam, or your screen recording tool, doesn't matter.Z You can show your face or not, and you're going to answer the following questions. What did my team work on this past week? What are we working on now? What issues are blocking us? Even if you're not especially blocked by anything, just say what are some of the challenges that you're facing or things that you're not sure of. To emphasize here, any team member can make the recording, so it doesn't have to be everybody on the team. I just want one representative from the team to make the stand-up and feel free to use your screen-sharing to show us any code snippets or cool results. It can be quite casual, this is not a presentation, this is a check-in. If you're facing something that is little difficult or incomplete, then that actually could be good for your classmates to see. They might have an opinion on it or a suggestion or it might just make somebody else who's dealing with that feel a little bit better, so please don't be afraid to be a little bit authentic here about what you're dealing with. One more thing, there are no hard limits on time, but the ideal would be about three to five minutes. If you go over, that's fine, if you go under, that can also be okay. We're not enforcing any limits, I just want you to do the exercise and help us understand what you were working on. Finally, let me tell you how to share your stand-up. What you're gonna do is upload your video to your U-M google Drive. You could also upload it to a personal YouTube channel or another video hosting service. It doesn't really matter as long as it's somewhere that you can upload the video and share a link to it. There is limited storage space on Slack, so please don't directly upload your video to Slack. Upload the video and then you're going to go in the stand-ups channel and copy and paste a link to the recording and make sure permissions are set so your classmates can view it. In the message body, please write your team name and then stand up. The team name is going to be the unique names of your teammates in alphabetical order. Unique names is just your University of Michigan email address. For example, it would be Alpha, Bravo, Charlie, stand up, and that's it. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one. Stand-ups are a really popular way that a lot of organizations help their members stay responsible for their work, stay on task, motivate one another, and just build a sense of community. It's just really cool to get to see what you're working on and to watch your project and other people's unfold over time. I am looking forward to seeing you in the stand-up channel.\""
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Transcript DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_numer</th>\n",
       "      <th>transcripts</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "      <td>Hi and welcome to the Master of Applied Data S...</td>\n",
       "      <td>3079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>630</td>\n",
       "      <td>All right. So, I got a question in the forum f...</td>\n",
       "      <td>9387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>630</td>\n",
       "      <td>Hi, Daniel. Hello, Cohan. Hi. How are you? Ver...</td>\n",
       "      <td>20115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>630</td>\n",
       "      <td>the red line. Now, next time we draw another 5...</td>\n",
       "      <td>20116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>630</td>\n",
       "      <td>In this video, we're going to take a closer lo...</td>\n",
       "      <td>16163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   course_numer                                        transcripts  length\n",
       "0           630  Hi and welcome to the Master of Applied Data S...    3079\n",
       "1           630  All right. So, I got a question in the forum f...    9387\n",
       "2           630  Hi, Daniel. Hello, Cohan. Hi. How are you? Ver...   20115\n",
       "3           630  the red line. Now, next time we draw another 5...   20116\n",
       "4           630  In this video, we're going to take a closer lo...   16163"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/transcripts\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate First Transcript to Summarize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#body = df.transcripts.iloc[6] #tried = [0, 5 \n",
    "#print(len(body.split('. ')))\n",
    "#print(body)\n",
    "\n",
    "body = lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert Extractive Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m      \n",
       "\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbody\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mratio\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_first\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0malgorithm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'kmeans'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_sentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_as_list\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m            Summarizer\n",
       "\u001b[0;31mString form:\u001b[0m     <summarizer.bert.Summarizer object at 0x7fbe25981fd0>\n",
       "\u001b[0;31mFile:\u001b[0m            ~/opt/anaconda3/lib/python3.7/site-packages/summarizer/bert.py\n",
       "\u001b[0;31mDocstring:\u001b[0m       <no docstring>\n",
       "\u001b[0;31mClass docstring:\u001b[0m Summarizer based on the BERT model.\n",
       "\u001b[0;31mInit docstring:\u001b[0m \n",
       "This is the main Bert Summarizer class.\n",
       "\n",
       ":param model: This parameter is associated with the inherit string parameters from the transformers library.\n",
       ":param custom_model: If you have a pre-trained model, you can add the model class here.\n",
       ":param custom_tokenizer: If you have a custom tokenizer, you can add the tokenizer here.\n",
       ":param hidden: This signifies which layer of the BERT model you would like to use as embeddings.\n",
       ":param reduce_option: Given the output of the bert model, this param determines how you want to reduce results.\n",
       ":param random_state: The random state to reproduce summarizations.\n",
       ":param hidden_concat: Whether or not to concat multiple hidden layers.\n",
       ":param gpu_id: GPU device index if CUDA is available. \n",
       "\u001b[0;31mCall docstring:\u001b[0m \n",
       "(utility that wraps around the run function)\n",
       "Preprocesses the sentences, runs the clusters to find the centroids, then combines the sentences.\n",
       "\n",
       ":param body: The raw string body to process.\n",
       ":param ratio: Ratio of sentences to use.\n",
       ":param min_length: Minimum length of sentence candidates to utilize for the summary.\n",
       ":param max_length: Maximum length of sentence candidates to utilize for the summary.\n",
       ":param use_first: Whether or not to use the first sentence.\n",
       ":param algorithm: Which clustering algorithm to use. (kmeans, gmm)\n",
       ":param num_sentences: Number of sentences to use (overrides ratio).\n",
       ":param return_as_list: Whether or not to return sentences as list.\n",
       ":return: A summary sentence.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#model = Summarizer(random_state=42)\n",
    "model = Summarizer('distilbert-base-uncased', hidden=[-2], hidden_concat=True, random_state=42)\n",
    "result = model(body, num_sentences=5, use_first=True)\n",
    "\n",
    "#hidden layer goes [-7, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Im the managing director at the Michigan Institute for data science. And in any team sport, its really hard to evaluate defense, especially as I mentioned in this previous video,  the traditional statistics that attract for defense are steals and blocks. Another, work thats been done with this data, and you could see how basketball is borrowing methods  from other fields is dividing this, the court reality to the player. And so you can see, how good a players at positioning themselves on defense,  on your own, the offense from looking at this kind of analysis  Next, so this is something that doesnt use the player tracking data uses video data. - Ivana do you want to answer another few questions.'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-7', '-6', '-5', '-4', '-3', '-2', '-1', '0', '1', '2', '3', '4', '5', '6']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16384\n"
     ]
    }
   ],
   "source": [
    "# Short and simple approach\n",
    "def permute(list1):\n",
    "    superSet = []\n",
    "    n = len(list1)\n",
    "\n",
    "    for i in range(2**n, 2**(n+1)):\n",
    "        seq = [x for x in bin(i)[3:]]\n",
    "        superSet.append(''.join([list1[j]\n",
    "                                 for j in range(n) if seq[j] == '1']))\n",
    "\n",
    "    return len(superSet)\n",
    "\n",
    "\n",
    "print(permute(strs))\n",
    "# Output : ['', 'C', 'B', 'BC', 'A', 'AC', 'AB', 'ABC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(itertools.product(strs, strs))\n",
    "unq = set(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = model(body, num_sentences=6, use_first=False) #min_length=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This module is about randomized experiments. As mentioned on the previous slide, some people did not receive the treatment to which they were assigned to, so there is a problem of noncompliance. The first outcome variable that we consider is the use of emergency departments.\n"
     ]
    }
   ],
   "source": [
    "full = ''.join(result)\n",
    "print(full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module is about randomized experiments. Now, this is easy to determine because of random assignment, we can just compare averages across treatment and control groups. Those who were offered to enroll in Medicaid went about 0.1 times more often to the ER as shown in Column 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBert Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s = SBertSummarizer('paraphrase-MiniLM-L6-v2', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m     \n",
       "\u001b[0mmodel_s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbody\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mratio\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_first\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0malgorithm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'kmeans'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_sentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_as_list\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m           SBertSummarizer\n",
       "\u001b[0;31mString form:\u001b[0m    <summarizer.sbert.SBertSummarizer object at 0x7fbe681cb050>\n",
       "\u001b[0;31mFile:\u001b[0m           ~/opt/anaconda3/lib/python3.7/site-packages/summarizer/sbert.py\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "The SBert Summarizer.\n",
       "\n",
       "This is based on the Sentence Bert Summarizer.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "SBert Summarizer.\n",
       "\n",
       ":param model: The model for the sentence transformer.\n",
       ":sentence_handler: The handler to process sentences. If want to use coreference, instantiate and pass.\n",
       ":param random_state: The random state to reproduce summarizations.\n",
       "\u001b[0;31mCall docstring:\u001b[0m\n",
       "(utility that wraps around the run function)\n",
       "Preprocesses the sentences, runs the clusters to find the centroids, then combines the sentences.\n",
       "\n",
       ":param body: The raw string body to process.\n",
       ":param ratio: Ratio of sentences to use.\n",
       ":param min_length: Minimum length of sentence candidates to utilize for the summary.\n",
       ":param max_length: Maximum length of sentence candidates to utilize for the summary.\n",
       ":param use_first: Whether or not to use the first sentence.\n",
       ":param algorithm: Which clustering algorithm to use. (kmeans, gmm)\n",
       ":param num_sentences: Number of sentences to use (overrides ratio).\n",
       ":param return_as_list: Whether or not to return sentences as list.\n",
       ":return: A summary sentence.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?model_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(body, num_sentences=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi and welcome to the Master of Applied Data Science Course and Causal Inference. For example, if you hit the snooze button on your alarm clock, then the alarm will stop. But sometimes actions are more complex, or we have to wait longer to observe the outcome. The problem is, that we cannot always run experiments. So, we often have to work with observational data, that is, data where we do not have full control over whether people take a certain action or not. We will talk about the core ideas behind those methods, their underlying assumptions, and what kind of causal effect they're estimating?\n"
     ]
    }
   ],
   "source": [
    "full = ''.join(result)\n",
    "print(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Out Different Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#dictionary of results\n",
    "Tracker = {}\n",
    "\n",
    "#params\n",
    "\n",
    "param_use_first = [True, False]\n",
    "param_algorithm = ['kmeans', 'gmm']\n",
    "param_num_sentences = [3, 5, 8]\n",
    "\n",
    "#models\n",
    "model_bert = Summarizer(random_state=42)\n",
    "model_sbert = SBertSummarizer('paraphrase-MiniLM-L6-v2', random_state=42)\n",
    "\n",
    "for u in param_use_first:\n",
    "    for a in param_algorithm:\n",
    "        for n in param_num_sentences:\n",
    "            result_bert = model_bert(body, num_sentences=n, use_first=u, algorithm=a) #min_length=60\n",
    "            full_bert = ''.join(result_bert)\n",
    "            result_sbert = model_sbert(body, num_sentences=n, use_first=u, algorithm=a)\n",
    "            full_sbert = ''.join(result_sbert)\n",
    "            Tracker['bert {} {} {}'.format(u, a, n)] = full_bert\n",
    "            Tracker['sbert {} {} {}'.format(u, a, n)] = full_sbert\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t***bert True kmeans 3***\n",
      "\n",
      "I mentioned to you that we're going to do some biweekly stand-ups, so here's what to do in a stand-up. Finally, let me tell you how to share your stand-up. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***sbert True kmeans 3***\n",
      "\n",
      "I mentioned to you that we're going to do some biweekly stand-ups, so here's what to do in a stand-up. It doesn't really matter as long as it's somewhere that you can upload the video and share a link to it. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***bert True kmeans 5***\n",
      "\n",
      "I mentioned to you that we're going to do some biweekly stand-ups, so here's what to do in a stand-up. Finally, let me tell you how to share your stand-up. You could also upload it to a personal YouTube channel or another video hosting service. It doesn't really matter as long as it's somewhere that you can upload the video and share a link to it. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***sbert True kmeans 5***\n",
      "\n",
      "I mentioned to you that we're going to do some biweekly stand-ups, so here's what to do in a stand-up. Upload the video and then you're going to go in the stand-ups channel and copy and paste a link to the recording and make sure permissions are set so your classmates can view it. In the message body, please write your team name and then stand up. Unique names is just your University of Michigan email address. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***bert True kmeans 8***\n",
      "\n",
      "I mentioned to you that we're going to do some biweekly stand-ups, so here's what to do in a stand-up. It can be quite casual, this is not a presentation, this is a check-in. Finally, let me tell you how to share your stand-up. What you're gonna do is upload your video to your U-M google Drive. It doesn't really matter as long as it's somewhere that you can upload the video and share a link to it. Upload the video and then you're going to go in the stand-ups channel and copy and paste a link to the recording and make sure permissions are set so your classmates can view it. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one. It's just really cool to get to see what you're working on and to watch your project and other people's unfold over time.\n",
      "\n",
      "\t***sbert True kmeans 8***\n",
      "\n",
      "I mentioned to you that we're going to do some biweekly stand-ups, so here's what to do in a stand-up. Z You can show your face or not, and you're going to answer the following questions. To emphasize here, any team member can make the recording, so it doesn't have to be everybody on the team. One more thing, there are no hard limits on time, but the ideal would be about three to five minutes. It doesn't really matter as long as it's somewhere that you can upload the video and share a link to it. In the message body, please write your team name and then stand up. Unique names is just your University of Michigan email address. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***bert True gmm 3***\n",
      "\n",
      "I mentioned to you that we're going to do some biweekly stand-ups, so here's what to do in a stand-up. Finally, let me tell you how to share your stand-up. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***sbert True gmm 3***\n",
      "\n",
      "I mentioned to you that we're going to do some biweekly stand-ups, so here's what to do in a stand-up. Upload the video and then you're going to go in the stand-ups channel and copy and paste a link to the recording and make sure permissions are set so your classmates can view it. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***bert True gmm 5***\n",
      "\n",
      "I mentioned to you that we're going to do some biweekly stand-ups, so here's what to do in a stand-up. Even if you're not especially blocked by anything, just say what are some of the challenges that you're facing or things that you're not sure of. Finally, let me tell you how to share your stand-up. What you're gonna do is upload your video to your U-M google Drive. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***sbert True gmm 5***\n",
      "\n",
      "I mentioned to you that we're going to do some biweekly stand-ups, so here's what to do in a stand-up. I just want one representative from the team to make the stand-up and feel free to use your screen-sharing to show us any code snippets or cool results. If you're facing something that is little difficult or incomplete, then that actually could be good for your classmates to see. It doesn't really matter as long as it's somewhere that you can upload the video and share a link to it. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***bert True gmm 8***\n",
      "\n",
      "I mentioned to you that we're going to do some biweekly stand-ups, so here's what to do in a stand-up. When it comes time for your stand-up, you're going to get on your webcam, or your screen recording tool, doesn't matter. Even if you're not especially blocked by anything, just say what are some of the challenges that you're facing or things that you're not sure of. To emphasize here, any team member can make the recording, so it doesn't have to be everybody on the team. If you go over, that's fine, if you go under, that can also be okay. You could also upload it to a personal YouTube channel or another video hosting service. Upload the video and then you're going to go in the stand-ups channel and copy and paste a link to the recording and make sure permissions are set so your classmates can view it. I am looking forward to seeing you in the stand-up channel.\n",
      "\n",
      "\t***sbert True gmm 8***\n",
      "\n",
      "I mentioned to you that we're going to do some biweekly stand-ups, so here's what to do in a stand-up. It can be quite casual, this is not a presentation, this is a check-in. They might have an opinion on it or a suggestion or it might just make somebody else who's dealing with that feel a little bit better, so please don't be afraid to be a little bit authentic here about what you're dealing with. It doesn't really matter as long as it's somewhere that you can upload the video and share a link to it. There is limited storage space on Slack, so please don't directly upload your video to Slack. In the message body, please write your team name and then stand up. Unique names is just your University of Michigan email address. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***bert False kmeans 3***\n",
      "\n",
      "Finally, let me tell you how to share your stand-up. It doesn't really matter as long as it's somewhere that you can upload the video and share a link to it. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***sbert False kmeans 3***\n",
      "\n",
      "It doesn't really matter as long as it's somewhere that you can upload the video and share a link to it. In the message body, please write your team name and then stand up. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***bert False kmeans 5***\n",
      "\n",
      "It can be quite casual, this is not a presentation, this is a check-in. Finally, let me tell you how to share your stand-up. What you're gonna do is upload your video to your U-M google Drive. It doesn't really matter as long as it's somewhere that you can upload the video and share a link to it. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***sbert False kmeans 5***\n",
      "\n",
      "Some of you who might have worked at tech companies or similar organizations might already know about them, but if you're new, here is roughly what we're going to do. They might have an opinion on it or a suggestion or it might just make somebody else who's dealing with that feel a little bit better, so please don't be afraid to be a little bit authentic here about what you're dealing with. It doesn't really matter as long as it's somewhere that you can upload the video and share a link to it. In the message body, please write your team name and then stand up. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***bert False kmeans 8***\n",
      "\n",
      "To emphasize here, any team member can make the recording, so it doesn't have to be everybody on the team. It can be quite casual, this is not a presentation, this is a check-in. They might have an opinion on it or a suggestion or it might just make somebody else who's dealing with that feel a little bit better, so please don't be afraid to be a little bit authentic here about what you're dealing with. Finally, let me tell you how to share your stand-up. What you're gonna do is upload your video to your U-M google Drive. You could also upload it to a personal YouTube channel or another video hosting service. It doesn't really matter as long as it's somewhere that you can upload the video and share a link to it. Upload the video and then you're going to go in the stand-ups channel and copy and paste a link to the recording and make sure permissions are set so your classmates can view it.\n",
      "\n",
      "\t***sbert False kmeans 8***\n",
      "\n",
      "I mentioned to you that we're going to do some biweekly stand-ups, so here's what to do in a stand-up. When it comes time for your stand-up, you're going to get on your webcam, or your screen recording tool, doesn't matter. It can be quite casual, this is not a presentation, this is a check-in. They might have an opinion on it or a suggestion or it might just make somebody else who's dealing with that feel a little bit better, so please don't be afraid to be a little bit authentic here about what you're dealing with. One more thing, there are no hard limits on time, but the ideal would be about three to five minutes. It doesn't really matter as long as it's somewhere that you can upload the video and share a link to it. Unique names is just your University of Michigan email address. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***bert False gmm 3***\n",
      "\n",
      "Finally, let me tell you how to share your stand-up. What you're gonna do is upload your video to your U-M google Drive. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***sbert False gmm 3***\n",
      "\n",
      "If you're facing something that is little difficult or incomplete, then that actually could be good for your classmates to see. It doesn't really matter as long as it's somewhere that you can upload the video and share a link to it. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***bert False gmm 5***\n",
      "\n",
      "Some of you who might have worked at tech companies or similar organizations might already know about them, but if you're new, here is roughly what we're going to do. Finally, let me tell you how to share your stand-up. What you're gonna do is upload your video to your U-M google Drive. You could also upload it to a personal YouTube channel or another video hosting service. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***sbert False gmm 5***\n",
      "\n",
      "They might have an opinion on it or a suggestion or it might just make somebody else who's dealing with that feel a little bit better, so please don't be afraid to be a little bit authentic here about what you're dealing with. One more thing, there are no hard limits on time, but the ideal would be about three to five minutes. It doesn't really matter as long as it's somewhere that you can upload the video and share a link to it. Unique names is just your University of Michigan email address. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n",
      "\n",
      "\t***bert False gmm 8***\n",
      "\n",
      "Some of you who might have worked at tech companies or similar organizations might already know about them, but if you're new, here is roughly what we're going to do. If you go over, that's fine, if you go under, that can also be okay. What you're gonna do is upload your video to your U-M google Drive. It doesn't really matter as long as it's somewhere that you can upload the video and share a link to it. Upload the video and then you're going to go in the stand-ups channel and copy and paste a link to the recording and make sure permissions are set so your classmates can view it. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one. It's just really cool to get to see what you're working on and to watch your project and other people's unfold over time. I am looking forward to seeing you in the stand-up channel.\n",
      "\n",
      "\t***sbert False gmm 8***\n",
      "\n",
      "I mentioned to you that we're going to do some biweekly stand-ups, so here's what to do in a stand-up. Z You can show your face or not, and you're going to answer the following questions. They might have an opinion on it or a suggestion or it might just make somebody else who's dealing with that feel a little bit better, so please don't be afraid to be a little bit authentic here about what you're dealing with. We're not enforcing any limits, I just want you to do the exercise and help us understand what you were working on. You could also upload it to a personal YouTube channel or another video hosting service. It doesn't really matter as long as it's somewhere that you can upload the video and share a link to it. The team name is going to be the unique names of your teammates in alphabetical order. Then I will be asking you to watch and comment on two other classmates stand-ups, one stand up per team every two weeks, don't worry, I will remind you when they are coming, you will not be in the dark about this, and I can also create, you know, I'll put one in the channel, a demo, so you can see a real one.\n"
     ]
    }
   ],
   "source": [
    "for x, i in Tracker.items():\n",
    "    print('\\n\\t***{}***\\n'.format(x))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Out Different Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#dictionary of results\n",
    "Tracker_hidden = {}\n",
    "\n",
    "#params\n",
    "\n",
    "param_hidden =  list(range(-7, 7))\n",
    "param_algorithm = 'gmm'\n",
    "param_num_sentences = 5\n",
    "param_use_first = True\n",
    "\n",
    "#models\n",
    "\n",
    "\n",
    "\n",
    "for h in param_hidden:\n",
    "    model_bert = Summarizer(random_state=42, hidden = h)\n",
    "    result_bert = model_bert(body, num_sentences=param_num_sentences, use_first=param_use_first, algorithm=param_algorithm) #min_length=60\n",
    "    full_bert = ''.join(result_bert)\n",
    "    Tracker['bert {} {} {}'.format(h, param_use_first, param_algorithm, param_num_sentences)] = full_bert         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, i in Tracker_hidden.items():\n",
    "    print('\\n\\t***{}***\\n'.format(x))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names\n",
    "feature_col = \"features\" # feature vector\n",
    "value_col = \"foldClass\" # fold class to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_json(\"./intermediate_data/foldClassification.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Word2vec Model\n",
    "We use the **ProtVec model** (Asgari et al.) to calculate a 100-dimensional feature vector for each protein sequence. ProtVec uses a Word2vec model (Mikolov et al.) that has been trained on 546,790 sequences in [Swiss-Prot](https://web.expasy.org/docs/swiss-prot_guideline.html) using 546,790  3 = 1,640,370 sequences of 3-grams. The 3-grams represent \"biological words\" in a protein sequence, e.g., sequence: SRMPSPP -> 3-grams: SRM RMP MPS PSP SPP. The **ProtVec** model is available for download at: https://github.com/ehsanasgari/Deep-Proteomics.\n",
    "\n",
    "Asgari E, Mofrad MR (2015) Continuous Distributed Representation of Biological Sequences for Deep Proteomics and Genomics, PLoS One. 10(11):e0141287. doi: [10.1371/journal.pone.0141287](https://doi.org/10.1371/journal.pone.0141287).\n",
    "\n",
    "Mikolov T, Sutskever I, Chen K, Corrado GS, Dean J, Distributed representations of words and phrases and their compositionality. In: [Advances in neural information processing systems; 2013. p. 31113119.](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read ProtVec Model\n",
    "Next we read a local copy of the ProtVec model. The ProtVec model is represented as a dictionary, with the 3-gram as the key and the 100-dimensional feature vector as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example ProtVec for 3-gram SRM:\n",
      " [-0.349053 -0.034172 -0.14602  -0.112906  0.318846  0.100117 -0.104718\n",
      " -0.194695 -0.08249   0.016351 -0.181182  0.109543  0.067238 -0.027135\n",
      "  0.222703  0.073312 -0.074177 -0.087137 -0.27853   0.003309 -0.065516\n",
      " -0.035587  0.042179  0.169955  0.155156 -0.07882   0.203758  0.129488\n",
      " -0.009507 -0.033186 -0.007172 -0.039388  0.243934  0.009303  0.043914\n",
      " -0.018962 -0.23077  -0.136273  0.027782  0.232346 -0.2341    0.102889\n",
      " -0.054253 -0.111376  0.106518 -0.027139 -0.139712 -0.049569  0.057983\n",
      " -0.157097  0.090227  0.0228    0.114038  0.017181 -0.015422 -0.035576\n",
      " -0.014446  0.000584 -0.292332  0.003074  0.097327  0.072325  0.138753\n",
      "  0.028772 -0.023035  0.024519  0.123589  0.021453  0.286168  0.094651\n",
      " -0.145597  0.132008 -0.104951  0.121934 -0.042467 -0.075287  0.306096\n",
      "  0.096278 -0.121827  0.167771  0.059359 -0.169576  0.018486 -0.143597\n",
      "  0.211764  0.171916  0.200995  0.190091 -0.142053  0.022641  0.204606\n",
      " -0.083642  0.016121 -0.147855  0.001436 -0.124035  0.00538  -0.177881\n",
      "  0.116058  0.195754]\n"
     ]
    }
   ],
   "source": [
    "protvec = protvectors.read_protvectors(\"./data/protVec_100d_3grams.csv\")\n",
    "\n",
    "print(\"Example ProtVec for 3-gram SRM:\\n\", protvec['SRM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 3-grams of the Protein Sequence\n",
    "Next, we create 3-grams for the protein sequences in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exptl.</th>\n",
       "      <th>FreeRvalue</th>\n",
       "      <th>R-factor</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>coil</th>\n",
       "      <th>foldClass</th>\n",
       "      <th>length</th>\n",
       "      <th>pdbChainId</th>\n",
       "      <th>resolution</th>\n",
       "      <th>secondary_structure</th>\n",
       "      <th>sequence</th>\n",
       "      <th>ngram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XRAY</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.469945</td>\n",
       "      <td>0.046448</td>\n",
       "      <td>0.483607</td>\n",
       "      <td>alpha</td>\n",
       "      <td>366</td>\n",
       "      <td>16VP.A</td>\n",
       "      <td>2.100</td>\n",
       "      <td>CCSCCCCCCCCHHHHHHHHHHHHTCTTHHHHHHHHHHCCCCCSTTS...</td>\n",
       "      <td>SRMPSPPMPVPPAALFNRLLDDLGFSAGPALCTMLDTWNEDLFSAL...</td>\n",
       "      <td>[SRM, RMP, MPS, PSP, SPP, PPM, PMP, MPV, PVP, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>XRAY</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.504630</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.490741</td>\n",
       "      <td>alpha</td>\n",
       "      <td>216</td>\n",
       "      <td>1PBW.B</td>\n",
       "      <td>2.000</td>\n",
       "      <td>CCCCCCCCCCCCCCHHHHCCTTSCSCHHHHHHHHHHHHHHTTCTTT...</td>\n",
       "      <td>MEADVEQQALTLPDLAEQFAPPDIAPPLLIKLVEAIEKKGLECSTL...</td>\n",
       "      <td>[MEA, EAD, ADV, DVE, VEQ, EQQ, QQA, QAL, ALT, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>XRAY</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.716172</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>alpha</td>\n",
       "      <td>303</td>\n",
       "      <td>4TQ3.A</td>\n",
       "      <td>2.408</td>\n",
       "      <td>CCCCCCCCCCCCCCCHHHHHHCGGGGHHHHHHHHHHHHHHCCTTSC...</td>\n",
       "      <td>MDSSLANINQIDVPSKYLRLLRPVAWLCFLLPYAVGFGFGITPNAS...</td>\n",
       "      <td>[MDS, DSS, SSL, SLA, LAN, ANI, NIN, INQ, NQI, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Exptl.  FreeRvalue  R-factor     alpha      beta      coil foldClass  \\\n",
       "1       XRAY        0.26      0.19  0.469945  0.046448  0.483607     alpha   \n",
       "1000    XRAY        0.23      0.18  0.504630  0.004630  0.490741     alpha   \n",
       "10002   XRAY        0.26      0.22  0.716172  0.006601  0.277228     alpha   \n",
       "\n",
       "       length pdbChainId  resolution  \\\n",
       "1         366     16VP.A       2.100   \n",
       "1000      216     1PBW.B       2.000   \n",
       "10002     303     4TQ3.A       2.408   \n",
       "\n",
       "                                     secondary_structure  \\\n",
       "1      CCSCCCCCCCCHHHHHHHHHHHHTCTTHHHHHHHHHHCCCCCSTTS...   \n",
       "1000   CCCCCCCCCCCCCCHHHHCCTTSCSCHHHHHHHHHHHHHHTTCTTT...   \n",
       "10002  CCCCCCCCCCCCCCCHHHHHHCGGGGHHHHHHHHHHHHHHCCTTSC...   \n",
       "\n",
       "                                                sequence  \\\n",
       "1      SRMPSPPMPVPPAALFNRLLDDLGFSAGPALCTMLDTWNEDLFSAL...   \n",
       "1000   MEADVEQQALTLPDLAEQFAPPDIAPPLLIKLVEAIEKKGLECSTL...   \n",
       "10002  MDSSLANINQIDVPSKYLRLLRPVAWLCFLLPYAVGFGFGITPNAS...   \n",
       "\n",
       "                                                   ngram  \n",
       "1      [SRM, RMP, MPS, PSP, SPP, PPM, PMP, MPV, PVP, ...  \n",
       "1000   [MEA, EAD, ADV, DVE, VEQ, EQQ, QQA, QAL, ALT, ...  \n",
       "10002  [MDS, DSS, SSL, SLA, LAN, ANI, NIN, INQ, NQI, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add column ngram to dataframe\n",
    "df['ngram'] = df.sequence.apply(protvectors.ngrammer, n=3)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Fixed-sized Feature Vector\n",
    "Here we create a 100-dimensional feature vector by adding up the ProtVectors for all 3-grams in a protein sequence and standardize each feature vector to zero-mean and unit-variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exptl.</th>\n",
       "      <th>FreeRvalue</th>\n",
       "      <th>R-factor</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>coil</th>\n",
       "      <th>foldClass</th>\n",
       "      <th>length</th>\n",
       "      <th>pdbChainId</th>\n",
       "      <th>resolution</th>\n",
       "      <th>secondary_structure</th>\n",
       "      <th>sequence</th>\n",
       "      <th>ngram</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XRAY</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.469945</td>\n",
       "      <td>0.046448</td>\n",
       "      <td>0.483607</td>\n",
       "      <td>alpha</td>\n",
       "      <td>366</td>\n",
       "      <td>16VP.A</td>\n",
       "      <td>2.100</td>\n",
       "      <td>CCSCCCCCCCCHHHHHHHHHHHHTCTTHHHHHHHHHHCCCCCSTTS...</td>\n",
       "      <td>SRMPSPPMPVPPAALFNRLLDDLGFSAGPALCTMLDTWNEDLFSAL...</td>\n",
       "      <td>[SRM, RMP, MPS, PSP, SPP, PPM, PMP, MPV, PVP, ...</td>\n",
       "      <td>[-2.618341208445193, -0.37215537192569575, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>XRAY</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.504630</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.490741</td>\n",
       "      <td>alpha</td>\n",
       "      <td>216</td>\n",
       "      <td>1PBW.B</td>\n",
       "      <td>2.000</td>\n",
       "      <td>CCCCCCCCCCCCCCHHHHCCTTSCSCHHHHHHHHHHHHHHTTCTTT...</td>\n",
       "      <td>MEADVEQQALTLPDLAEQFAPPDIAPPLLIKLVEAIEKKGLECSTL...</td>\n",
       "      <td>[MEA, EAD, ADV, DVE, VEQ, EQQ, QQA, QAL, ALT, ...</td>\n",
       "      <td>[-2.4130836608297224, -0.5122827315971855, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>XRAY</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.716172</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>alpha</td>\n",
       "      <td>303</td>\n",
       "      <td>4TQ3.A</td>\n",
       "      <td>2.408</td>\n",
       "      <td>CCCCCCCCCCCCCCCHHHHHHCGGGGHHHHHHHHHHHHHHCCTTSC...</td>\n",
       "      <td>MDSSLANINQIDVPSKYLRLLRPVAWLCFLLPYAVGFGFGITPNAS...</td>\n",
       "      <td>[MDS, DSS, SSL, SLA, LAN, ANI, NIN, INQ, NQI, ...</td>\n",
       "      <td>[-2.6375752438981404, 0.18385725798670652, 0.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Exptl.  FreeRvalue  R-factor     alpha      beta      coil foldClass  \\\n",
       "1       XRAY        0.26      0.19  0.469945  0.046448  0.483607     alpha   \n",
       "1000    XRAY        0.23      0.18  0.504630  0.004630  0.490741     alpha   \n",
       "10002   XRAY        0.26      0.22  0.716172  0.006601  0.277228     alpha   \n",
       "\n",
       "       length pdbChainId  resolution  \\\n",
       "1         366     16VP.A       2.100   \n",
       "1000      216     1PBW.B       2.000   \n",
       "10002     303     4TQ3.A       2.408   \n",
       "\n",
       "                                     secondary_structure  \\\n",
       "1      CCSCCCCCCCCHHHHHHHHHHHHTCTTHHHHHHHHHHCCCCCSTTS...   \n",
       "1000   CCCCCCCCCCCCCCHHHHCCTTSCSCHHHHHHHHHHHHHHTTCTTT...   \n",
       "10002  CCCCCCCCCCCCCCCHHHHHHCGGGGHHHHHHHHHHHHHHCCTTSC...   \n",
       "\n",
       "                                                sequence  \\\n",
       "1      SRMPSPPMPVPPAALFNRLLDDLGFSAGPALCTMLDTWNEDLFSAL...   \n",
       "1000   MEADVEQQALTLPDLAEQFAPPDIAPPLLIKLVEAIEKKGLECSTL...   \n",
       "10002  MDSSLANINQIDVPSKYLRLLRPVAWLCFLLPYAVGFGFGITPNAS...   \n",
       "\n",
       "                                                   ngram  \\\n",
       "1      [SRM, RMP, MPS, PSP, SPP, PPM, PMP, MPV, PVP, ...   \n",
       "1000   [MEA, EAD, ADV, DVE, VEQ, EQQ, QQA, QAL, ALT, ...   \n",
       "10002  [MDS, DSS, SSL, SLA, LAN, ANI, NIN, INQ, NQI, ...   \n",
       "\n",
       "                                                features  \n",
       "1      [-2.618341208445193, -0.37215537192569575, 0.1...  \n",
       "1000   [-2.4130836608297224, -0.5122827315971855, 0.1...  \n",
       "10002  [-2.6375752438981404, 0.18385725798670652, 0.2...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[feature_col] = df.ngram.apply(protvectors.apply_protvectors, protvec=protvec)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save DataFrame with Feature Vectors\n",
    "We save the dataset with protein sequence, fold classification, and feature vectors as a Pandas dataframe for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"./intermediate_data/features.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next step\n",
    "After you saved the dataset here, run the next step in the workflow [3-FitModel.ipynb](./3-FitModel.ipynb) or go back go back to [0-Workflow.ipynb](./0-Workflow.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Authors:** [Peter W. Rose](mailto:pwrose.ucsd@gmail.com), Shih-Cheng Huang, UC San Diego, October 1, 2018\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
