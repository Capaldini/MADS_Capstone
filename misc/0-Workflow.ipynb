{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The notebooks in this directory demonstrate how to build a  machine learning tool to extract hyperlinks from video transcripts**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coursera course content videos have two key information components - video and transcript. Content within the trascripts can often be hard to undersand and require further search methods such a googling and reading wikipedia pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important topics within a transcript include:\n",
    "* Key Terms:\n",
    "* Books: contains predominantly beta sheets\n",
    "* People: contains alpha helices and beta sheets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "This notebook demonstrates how to create a hyperlink based web application for videotranscripts.\n",
    "\n",
    "**Run the following notebooks and explore how we build the model and deployed it to our website.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we extract the raw coursera data with all of the transcripts used in the MADS program.\n",
    "\n",
    "[Coursera Downloader Documentation](https://github.com/coursera-dl/coursera-dl)\n",
    "\n",
    "Run the following notebook to extract the raw coursera data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1-CreateDataset.ipynb](./1-CreateDataset.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook saves the dataset in the folder `./data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the raw data has been gathered, we clean the dataset to only keep the course transcripts.\n",
    "\n",
    "Run the following notebook to extract the transcripts from the raw course data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2-CleanDataset.ipynb](./2-CleanDataset.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook saves the dataset in the file `./intermediate_data/transcripts.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transcript Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then next step is to generate summaries for each of the transcripts. Here we use the Bert Extractive Summarizer and SentenceTransformers libraries to generate our transcript summaries.\n",
    "\n",
    "[Bert Summarizer Documentation](https://pypi.org/project/bert-extractive-summarizer/#description)\n",
    "\n",
    "[SentenceTransformers Documentation](https://www.sbert.net/)\n",
    "\n",
    "\n",
    "Run the following notebook to generate transcript summaries. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3-TranscriptSummarization.ipynb](./3-TranscriptSummarization.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook saves the dataset with feature vectors in the file `./intermediate_data/features.json`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Keyword Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperlink Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we fit a 3-state classification model using the feature vectors and the given fold classification from the Protein Data Bank dataset.\n",
    "\n",
    "Run the following notebook to fit a machine learning model on a training set and evaluate its performance on a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3-FitModel.ipynb](./3-FitModel.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook saves the classification model in the file `./intermediate_data/classifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Manual Evaluation\n",
    "How accurate is the url for the model? Is it relevant? What percentage of the URL's make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Generalization\n",
    "Does the model generalize to other course transcripts? (Perry Samsom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Deploy Model Product Demo on Website (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the trained model from the previous step to our Capstone Website using Anvile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4-MLProduct.ipynb](./4-MLProduct.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version and Hardware Information\n",
    "Here we use the watermark extension to print software, operating system, and hardware version information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.7.4\n",
      "IPython version      : 7.8.0\n",
      "\n",
      "ipywidgets           : 7.5.1\n",
      "matplotlib           : 2.2.3\n",
      "numpy                : 1.21.6\n",
      "pandas               : 0.25.1\n",
      "sklearn              : 1.0.2\n",
      "gensim               : 4.2.0\n",
      "tqdm                 : 4.64.0\n",
      "nltk                 : 3.7\n",
      "collections          : unknown\n",
      "spacy                : 3.4.0\n",
      "string               : unknown\n",
      "keybert              : 0.5.1\n",
      "keyphrase_vectorizers: 0.0.10\n",
      "\n",
      "Compiler    : Clang 4.0.1 (tags/RELEASE_401/final)\n",
      "OS          : Darwin\n",
      "Release     : 21.5.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -m -p ipywidgets,matplotlib,numpy,pandas,sklearn,gensim,tqdm,nltk,collections,spacy,string,keybert,keyphrase_vectorizers,wikipedia,getpass, Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Authors:** [Wei Zhou](mailto:weiwzhou@umich.edu), [Nick Capaldini](mailto:nickcaps@umich.edu), University of Michigan, July 30, 2022\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
